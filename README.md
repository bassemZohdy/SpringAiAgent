# Spring AI Agent Project

A multi-module project providing unified OpenAI-compatible chat completions API with streaming support, multiple LLM providers, and modern Angular UI.

## ğŸš€ Features

- **Unified API**: Single `/v1/chat/completions` endpoint for streaming and non-streaming
- **OpenAI Integration**: Full OpenAI API compatibility with gpt-5-nano and gpt-4 models
- **Streaming Support**: Real-time Server-Sent Events (SSE) streaming
- **Thread Management**: OpenAI Assistants API-compatible conversation threads
- **Modern UI**: Angular Material Design interface with streaming toggle
- **OpenAI Compatible**: Drop-in replacement for OpenAI Chat Completions API
- **Agent Framework**: Extensible agent architecture with task and chat specializations

## ğŸ—ï¸ Architecture Overview

```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[Angular UI<br/>Material Design<br/>Streaming Chat Interface]
    end

    subgraph "API Gateway Layer"
        API[Spring Boot REST API<br/>OpenAI Compatible Endpoints]
        ChatController[ChatController<br/>/v1/chat/completions]
        ThreadController[ThreadController<br/>/v1/threads]
        AgentController[AgentController<br/>/api/v1/agent]
    end

    subgraph "Service Layer"
        ChatService[ChatService<br/>Provider Abstraction]
        AgentChatService[AgentChatService<br/>Agent Framework Integration]
        MemoryAdvisor[MemoryAdvisor<br/>Context Injection]
    end

    subgraph "Agent Framework Layer"
        Agent[Agent Interface<br/>Base Agent Abstraction]
        TaskAgent[TaskAgent<br/>Discrete Task Processing]
        ChatAgent[ChatAgent<br/>Conversational Interactions]
        BaseAgent[BaseAgent<br/>State Machine & Lifecycle]
    end

    subgraph "Metrics & Memory Layer"
        Metrics[AgentMetrics<br/>TaskAgentMetrics<br/>ChatAgentMetrics]
        Memory[AgentMemory<br/>Execution History & Learning]
    end

    subgraph "Provider Layer"
        OpenAI[OpenAI Provider<br/>Spring AI Integration]
        LMStudio[LM Studio Provider<br/>Local LLM Support]
    end

    UI <--> API
    API <--> ChatController
    API <--> ThreadController
    API <--> AgentController

    ChatController <--> ChatService
    AgentController <--> AgentChatService
    ChatService <--> MemoryAdvisor

    AgentChatService <--> TaskAgent
    AgentChatService <--> ChatAgent

    TaskAgent <--> BaseAgent
    ChatAgent <--> BaseAgent
    BaseAgent <--> Agent

    BaseAgent <--> Metrics
    BaseAgent <--> Memory

    ChatService <--> OpenAI
    ChatService <--> LMStudio
```

## ğŸ“‹ Module Architecture

```mermaid
graph LR
    subgraph "Multi-Module Structure"
        A[agent<br/>Core Agent Library]
        B[spring-ai-agent<br/>Spring Boot Application]
        C[ui<br/>Angular Frontend]
    end

    A -->|Maven Dependency| B
    C -->|REST API Calls| B

    subgraph "Agent Module Details"
        A1[Agent Interfaces]
        A2[BaseAgent Implementation]
        A3[Metrics System]
        A4[Memory System]
        A5[Task Abstractions]
    end

    A --> A1
    A --> A2
    A --> A3
    A --> A4
    A --> A5
```

## ğŸ”„ Agent State Machine

```mermaid
stateDiagram-v2
    [*] --> CREATED
    CREATED --> STARTING: start()
    STARTING --> STARTED: doStart()
    STARTED --> PAUSING: pause()
    STARTED --> STOPPING: stop()
    STARTED --> RESETTING: reset()

    PAUSING --> PAUSED: doPause()
    PAUSED --> STARTING: start()
    PAUSED --> STOPPING: stop()
    PAUSED --> RESETTING: reset()

    STOPPING --> STOPPED: doStop()
    STOPPED --> STARTING: start()
    STOPPED --> RESETTING: reset()

    RESETTING --> CREATED: doReset()

    STARTING --> ERROR: failure
    PAUSING --> ERROR: failure
    STOPPING --> ERROR: failure
    RESETTING --> ERROR: failure

    ERROR --> RESETTING: reset()
```

## ğŸ“Š Metrics Hierarchy

```mermaid
classDiagram
    class AgentMetrics {
        <<abstract>>
        +recordOperationStarted()
        +recordOperationSucceeded()
        +recordOperationFailed()
        +getSuccessRate()
        +getThroughput()
        +getUptime()
    }

    class TaskAgentMetrics {
        +recordTaskSucceeded()
        +recordTaskFailed()
        +recordTaskRetry()
        +getTaskSuccessRate()
        +getRetryRate()
        +getAverageInputSize()
        +getPriorityDistribution()
    }

    class ChatAgentMetrics {
        +recordConversationStarted()
        +recordConversationCompleted()
        +recordMessageProcessed()
        +getConversationCompletionRate()
        +getAverageMessagesPerConversation()
        +getTokenEfficiency()
    }

    AgentMetrics <|-- TaskAgentMetrics
    AgentMetrics <|-- ChatAgentMetrics
```

## ğŸ¯ Agent Specialization Patterns

```mermaid
graph TB
    subgraph "Agent Hierarchy"
        Base[Agent Interface<br/>Generic Operations]

        subgraph "Specialized Agents"
            Task[TaskAgent<br/>Process(TASK) â†’ RESULT]
            Chat[ChatAgent<br/>Chat(REQUEST) â†’ RESPONSE]
            AI[AiAgent<br/>Transform Pipeline]
        end

        subgraph "Implementation"
            Impl[BaseAgent<br/>State Machine<br/>Single-threaded<br/>Metrics & Memory]
        end
    end

    Base <|-- Task
    Base <|-- Chat
    Base <|-- AI

    Task <|-- Impl
    Chat <|-- Impl
    AI <|-- Impl

    subgraph "Use Cases"
        UC1[Data Processing<br/>Document Analysis<br/>Code Generation]
        UC2[Customer Service<br/>Personal Assistants<br/>Tutors]
        UC3[LLM Integration<br/>Content Generation<br/>Analysis]
    end

    Task --> UC1
    Chat --> UC2
    AI --> UC3
```

## ğŸŒ API Request Flow

```mermaid
sequenceDiagram
    participant Client as Client Application
    participant API as Spring Boot API
    participant Agent as Agent Framework
    participant Provider as LLM Provider
    participant Memory as Agent Memory

    Client->>API: POST /v1/chat/completions
    API->>API: Parse Request & Validate

    alt Agent Framework Mode
        API->>Agent: process(task) or chat(request)
        Agent->>Agent: Record metrics start
        Agent->>Memory: Check memory for context
        Agent->>Provider: LLM processing
        Provider-->>Agent: LLM response
        Agent->>Memory: Store execution & learnings
        Agent->>Agent: Record metrics success
        Agent-->>API: Result with metadata
    else Direct Provider Mode
        API->>Provider: Direct LLM call
        Provider-->>API: LLM response
    end

    alt Streaming Request
        API-->>Client: SSE stream chunks
    else Non-Streaming
        API-->>Client: Complete response
    end
```

## ğŸš€ Deployment Architecture

```mermaid
graph TB
    subgraph "Development Environment"
        DevUI[Angular Dev Server<br/>:4200]
        DevAPI[Spring Boot Dev<br/>:8080]
        DevProxy[Angular Proxy<br/>â†’ API]

        DevUI <--> DevProxy
        DevProxy --> DevAPI
    end

    subgraph "Production Docker"
        LB[Load Balancer<br/>Nginx/Cloudflare]

        subgraph "App Services"
            UI[Angular Container<br/>:80]
            API1[Spring Boot Container 1<br/>:8080]
            API2[Spring Boot Container 2<br/>:8080]
        end

        subgraph "External Services"
            OpenAI[OpenAI API]
            LM[LM Studio<br/>Optional Local]
        end

        LB --> UI
        LB --> API1
        LB --> API2

        API1 --> OpenAI
        API2 --> OpenAI
        API1 --> LM
        API2 --> LM
    end
```

## ğŸ“ Project Structure

```
spring-ai-agent/
â”œâ”€â”€ README.md              # Main project overview
â”œâ”€â”€ docker-compose.yml     # Docker configuration
â”œâ”€â”€ run-dev.bat           # Development launcher (Windows)
â”œâ”€â”€ pom.xml               # Maven configuration
â”‚
â”œâ”€â”€ agent/                # ğŸ¤– Agent library
â”‚   â”œâ”€â”€ src/main/java/ai/demo/agent/
â”‚   â”‚   â”œâ”€â”€ base/                   # Base abstractions
â”‚   â”‚   â”‚   â”œâ”€â”€ Agent.java              # Base agent interface
â”‚   â”‚   â”‚   â”œâ”€â”€ AiAgent.java            # AI/LLM specialization
â”‚   â”‚   â”‚   â”œâ”€â”€ BaseAgent.java          # Abstract implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentConfiguration.java # Configuration management
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentException.java     # Exception handling
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentMemory.java        # Memory system
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentState.java         # State enumeration
â”‚   â”‚   â”‚   â””â”€â”€ task/                   # Task abstractions
â”‚   â”‚   â”œâ”€â”€ chat/                   # Chat agent specialization
â”‚   â”‚   â”‚   â””â”€â”€ ChatAgent.java         # Conversational agent interface
â”‚   â”‚   â”œâ”€â”€ task/                   # Task agent specialization
â”‚   â”‚   â”‚   â””â”€â”€ TaskAgent.java         # Discrete task processing interface
â”‚   â”‚   â””â”€â”€ metrics/                # Performance metrics
â”‚   â”‚       â”œâ”€â”€ AgentMetrics.java       # Base metrics class
â”‚   â”‚       â”œâ”€â”€ TaskAgentMetrics.java   # Task-specific metrics
â”‚   â”‚       â””â”€â”€ ChatAgentMetrics.java   # Chat-specific metrics
â”‚   â””â”€â”€ src/test/java/              # Agent tests
â”‚
â”œâ”€â”€ spring-ai-agent/     # ğŸŒ Spring Boot application
â”‚   â”œâ”€â”€ src/main/java/ai/demo/springagent/
â”‚   â”‚   â”œâ”€â”€ controller/             # REST controllers
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatController.java
â”‚   â”‚   â”‚   â”œâ”€â”€ ThreadController.java
â”‚   â”‚   â”‚   â””â”€â”€ AgentController.java
â”‚   â”‚   â”œâ”€â”€ service/                # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatService.java
â”‚   â”‚   â”‚   â””â”€â”€ AgentChatService.java
â”‚   â”‚   â”œâ”€â”€ provider/               # LLM providers
â”‚   â”‚   â””â”€â”€ config/                 # Configuration
â”‚   â””â”€â”€ src/test/                   # Integration tests
â”‚
â”œâ”€â”€ ui/                  # ğŸ¨ Angular frontend
â”‚   â”œâ”€â”€ src/app/
â”‚   â”‚   â”œâ”€â”€ services/               # API services
â”‚   â”‚   â”œâ”€â”€ components/             # UI components
â”‚   â”‚   â””â”€â”€ models/                 # TypeScript interfaces
â”‚   â””â”€â”€ src/test/                   # Frontend tests
â”‚
â”œâ”€â”€ docs/                # ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md          # Documentation index
â”‚   â”œâ”€â”€ ARCHITECTURE.md    # System architecture
â”‚   â”œâ”€â”€ API_USAGE.md       # API documentation
â”‚   â”œâ”€â”€ AGENTS.md          # Agent framework guide
â”‚   â”œâ”€â”€ PROJECT_STATUS.md  # Project status
â”‚   â”œâ”€â”€ TODO.md            # Project roadmap
â”‚   â””â”€â”€ ...other docs
â”‚
â”œâ”€â”€ scripts/             # ğŸš€ Development scripts
â”‚   â”œâ”€â”€ run-dev.sh        # Development launcher (Linux/macOS)
â”‚   â”œâ”€â”€ run-dev.bat       # Development launcher (Windows)
â”‚   â”œâ”€â”€ start.sh          # Service starter (Linux/macOS)
â”‚   â””â”€â”€ start.bat         # Service starter (Windows)
â”‚
â”œâ”€â”€ tools/               # ğŸ”§ Development tools
â”‚   â”œâ”€â”€ mock-servers/     # Mock servers for testing
â”‚   â”‚   â”œâ”€â”€ mock-server.js
â”‚   â”‚   â””â”€â”€ simple-mock-server.js
â”‚   â””â”€â”€ testing/          # Testing utilities
â”‚       â””â”€â”€ test-agent-integration.js
â”‚
â””â”€â”€ config/              # âš™ï¸ Configuration files
    â”œâ”€â”€ vscode/           # VSCode settings
    â”œâ”€â”€ claude/           # Claude Code settings
    â””â”€â”€ env/              # Environment templates
```

## Quick Start with Docker

1. **Clone and setup environment**:
   ```bash
   cp .env.example .env
   # Edit .env and add your OpenAI API key
   ```

2. **Start all services**:
   ```bash
   docker-compose up -d
   ```

3. **Access the application**:
   - **Chat UI**: http://localhost:4200 (with streaming toggle and provider selection)
   - **API**: http://localhost:8080/v1 (OpenAI-compatible endpoints)
   - **Health Check**: http://localhost:8080/actuator/health
   - **API Docs**: See [API_USAGE.md](./API_USAGE.md)

## Development Setup

### Prerequisites
- Java 21
- Maven 3.9+
- Node.js 18+
- Docker & Docker Compose (for production deployment)

### Quick Development Start
```bash
# Linux/macOS
./scripts/run-dev.sh

# Windows
run-dev.bat
```

## ğŸ”Œ API Endpoints

### Chat Completions
- `POST /v1/chat/completions` - Unified chat completions (streaming/non-streaming)
  - Query params: `stream=true/false`
  - Headers: `X-LLM-Provider: openai`

### Agent Framework
- `POST /api/v1/agent/chat` - Chat via agent framework
- `POST /api/v1/agent/chat/memory` - Chat with memory context
- `GET /api/v1/agent/metrics` - Agent performance metrics
- `GET /api/v1/agent/health` - Agent health status
- `POST /api/v1/agent/memory/compact` - Compact agent memory
- `GET /api/v1/agent/capabilities` - Agent capabilities

### Thread Management
- `POST /v1/threads` - Create conversation thread
- `GET /v1/threads/{id}` - Get thread details
- `GET /v1/threads/{id}/messages` - List thread messages
- `POST /v1/threads/{id}/messages` - Add message to thread

### System
- `GET /v1/models` - Available models
- `GET /actuator/health` - Health check

## ğŸ“– Documentation

- [API Usage Guide](./API_USAGE.md) - Comprehensive API documentation with examples
- [Agent Development Guide](./AGENTS.md) - Agent framework development guidelines
- [Deployment Guide](./docs/deployment-guide.md) - Docker, container registry, and Kubernetes instructions
- [Troubleshooting Guide](./docs/troubleshooting.md) - Common fixes for backend, UI, and deployment issues
- [TODO List](./TODO.md) - Project roadmap and task tracking
- [CLAUDE.md](./CLAUDE.md) - Development setup and build instructions

## ğŸ¤ Contributing

Refer to [TODO.md](./TODO.md) for current tasks and roadmap. New tasks can be assigned using the standard format provided in the TODO file.
